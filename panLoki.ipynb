{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62426da5-ef5c-466c-81fa-b881a57ee04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import param\n",
    "import panel as pn\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from Bio import SeqIO, AlignIO\n",
    "from io import StringIO\n",
    "import os\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqUtils import gc_fraction\n",
    "from glob import glob\n",
    "import shutil\n",
    "import csv\n",
    "from collections import Counter\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from bokeh.models import ColumnDataSource, Plot, Grid, Range1d\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models.glyphs import Text, Rect\n",
    "from bokeh.layouts import gridplot\n",
    "import pyperclip as pc\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mplc\n",
    "import re\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fce60bc-04ed-43a0-956c-f5fc9bca1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter config with updated file input settings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90d88f05-a529-4cf0-b331-85fbefa97355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.3.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.5.0/dist/js/tabulator.min', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'plotly': 'https://cdn.plot.ly/plotly-2.18.0.min', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"tabulator\"], function(Tabulator) {\n",
       "\twindow.Tabulator = Tabulator\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"moment\"], function(moment) {\n",
       "\twindow.moment = moment\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"plotly\"], function(Plotly) {\n",
       "\twindow.Plotly = Plotly\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 12;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.6/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.6/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Plotly'] !== undefined) && (!(window['Plotly'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.6/dist/bundled/plotlyplot/plotly-2.18.0.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.6/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.6/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/jquery/jquery.slim.min.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/plotlyplot/plotly-2.18.0.min.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.min.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.3.min.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [\"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/css/tabulator_simple.min.css\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.css\"];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "\ttry {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "\t} catch(e) {\n",
       "\t  if (!reloading) {\n",
       "\t    throw e;\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.5.0/dist/js/tabulator.min', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'plotly': 'https://cdn.plot.ly/plotly-2.18.0.min', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"plotly\"], function(Plotly) {\n\twindow.Plotly = Plotly\n\ton_load()\n      })\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 12;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.6/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.6/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Plotly'] !== undefined) && (!(window['Plotly'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.6/dist/bundled/plotlyplot/plotly-2.18.0.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.6/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.6/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/jquery/jquery.slim.min.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/plotlyplot/plotly-2.18.0.min.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.min.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.3.min.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js\", \"https://cdn.holoviz.org/panel/1.3.6/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [\"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/css/tabulator_simple.min.css\", \"https://cdn.holoviz.org/panel/1.3.6/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.css\"];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='f1fe5710-d443-4a4b-befa-466505224201'>\n",
       "  <div id=\"d3bda55e-53d4-4c79-99b5-6eaf3247ea4f\" data-root-id=\"f1fe5710-d443-4a4b-befa-466505224201\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"9d905521-a5e0-4853-9a6e-d189070515bc\":{\"version\":\"3.3.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"f1fe5710-d443-4a4b-befa-466505224201\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"083530d1-b2fa-4689-ac2d-d8c41730d446\",\"attributes\":{\"plot_id\":\"f1fe5710-d443-4a4b-befa-466505224201\",\"comm_id\":\"859efa2c1395453591d8f017e2a31ccc\",\"client_comm_id\":\"530c8772a5f74da4a6a179ecde0c18c8\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"9d905521-a5e0-4853-9a6e-d189070515bc\",\"roots\":{\"f1fe5710-d443-4a4b-befa-466505224201\":\"d3bda55e-53d4-4c79-99b5-6eaf3247ea4f\"},\"root_ids\":[\"f1fe5710-d443-4a4b-befa-466505224201\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined && ( root['Tabulator'] !== undefined) && ( root['Plotly'] !== undefined) && ( root['jsPanel'] !== undefined) && ( root['Tabulator'] !== undefined) && ( root['Plotly'] !== undefined))\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "f1fe5710-d443-4a4b-befa-466505224201"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pn.extension('floatpanel', 'tabulator', 'plotly')\n",
    "pipeline = pn.pipeline.Pipeline(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0117480d-0216-42db-b1fd-be45cb37e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder= os.getcwd()\n",
    "mafft_folder=f\"{project_folder}/aligned\"\n",
    "tree_folder=f\"{project_folder}/trees\"\n",
    "images_folder = f\"{project_folder}/images\"\n",
    "blast_folder = f\"{project_folder}/blast_results\"\n",
    "export_folder = f\"{project_folder}/export\"\n",
    "\n",
    "show_float = True\n",
    "num_cpus = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9485f3e2-245c-406c-97b1-85a50dd18bdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 57)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:57\u001b[0;36m\u001b[0m\n\u001b[0;31m    if os.path.exists(export_folder) == False:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class Genomes(param.Parameterized):\n",
    "\n",
    "    def view(self):\n",
    "        def create(event):\n",
    "            global project_folder\n",
    "            if project_path_input.value == '':\n",
    "                project_path_input.value = project_path_input.placeholder\n",
    "            if project_path_input.value[-1] == '/':\n",
    "                project_folder = f\"{project_path_input.value}{project_name.value}\"\n",
    "            else:\n",
    "                project_folder = f\"{project_path_input.value}/{project_name.value}\"\n",
    "            if not os.path.exists(project_folder):\n",
    "                os.mkdir(project_folder)\n",
    "                os.chdir(project_folder)\n",
    "                project_structure()\n",
    "                floatpanel.visible = False\n",
    "            else:\n",
    "                project_name.value=\"\"\n",
    "                project_name.placeholder = \"This folder already exists!\"\n",
    "\n",
    "        def open_proj(event):\n",
    "            global project_folder\n",
    "            if os.path.exists(open_proj_name.value) and os.path.isdir(open_proj_name.value):\n",
    "                project_folder = open_proj_name.value\n",
    "                os.chdir(project_folder)\n",
    "                project_structure()\n",
    "                floatpanel.visible = False\n",
    "                with os.scandir(project_folder) as entries:\n",
    "                    for entry in entries:\n",
    "                        if 'sequence_stats.csv' == entry.name:\n",
    "                            sequence_df.value = pd.read_csv('sequence_stats.csv', index_col=0)\n",
    "                update_df()\n",
    "            else:\n",
    "                open_proj_name.value=\"\"\n",
    "                open_proj_name.placeholder = \"This folder does not exist!\"\n",
    "        \n",
    "        def project_structure():\n",
    "            global show_float\n",
    "            global mafft_folder\n",
    "            global tree_folder\n",
    "            global image_folder\n",
    "            global blast_folder\n",
    "            global export_folder\n",
    "            show_float = False\n",
    "            mafft_folder=f\"{project_folder}/aligned\"\n",
    "            tree_folder=f\"{project_folder}/trees\"\n",
    "            images_folder = f\"{project_folder}/images\"\n",
    "            blast_folder = f\"{project_folder}/blast_results\"\n",
    "            export_folder = f\"{project_folder}/export\"\n",
    "            if os.path.exists(mafft_folder) == False:\n",
    "                os.mkdir(os.path.join(project_folder, \"aligned\"))\n",
    "            if os.path.exists(tree_folder) == False:\n",
    "                os.mkdir(os.path.join(project_folder, \"trees\"))\n",
    "            if os.path.exists(images_folder) == False:\n",
    "                os.mkdir(os.path.join(project_folder, \"images\"))\n",
    "            if os.path.exists(blast_folder) == False:\n",
    "                os.mkdir(os.path.join(project_folder, \"blast_results\"))\n",
    "            if os.path.exists(export_folder) == False:\n",
    "                os.mkdir(os.path.join(project_folder, \"export\"))\n",
    "\n",
    "        def update_df():\n",
    "            if os.path.isfile(f'{project_folder}/sequence_stats.csv') == True: \n",
    "                sequence_df.value = pd.read_csv('sequence_stats.csv', index_col=0)\n",
    "            loading.visible = True\n",
    "            loading.value = True\n",
    "            loading.name = \"Updating sequence statistic...\"\n",
    "            genome_to_proteins=[]\n",
    "            dict_list = []\n",
    "            gbff_names=glob(f'{project_folder}/*.gbff')\n",
    "            name_df = pd.read_csv('info_table.csv', index_col=0, names=['organism', 'strain', 'tax_id'])\n",
    "            for genbank_file in gbff_names:\n",
    "                genome_name = os.path.basename(genbank_file).split('.gbff')[0]\n",
    "                if not genome_name in sequence_df.value.index.tolist():\n",
    "                    genome_length = 0\n",
    "                    count = 0\n",
    "                    plasmid_counter = 0\n",
    "                    tot = 0\n",
    "                    n50 = 0\n",
    "                    rRNA_count = 0\n",
    "                    tRNA_count = 0\n",
    "                    protein_number = 0\n",
    "                    try:\n",
    "                        organism = name_df.at[genome_name, 'organism']\n",
    "                        strain = name_df.at[genome_name, 'strain']\n",
    "                        tax_id = name_df.at[genome_name, 'tax_id']\n",
    "                    except:\n",
    "                        organism = '-'\n",
    "                        strain = '-'\n",
    "                        tax_id = '-'\n",
    "                    seq_concat = \"\"\n",
    "                    for gb_obj in SeqIO.parse(genbank_file,'genbank'):\n",
    "                        genome_length += len(gb_obj.seq)\n",
    "                        count += 1\n",
    "                        seq_concat += gb_obj.seq\n",
    "                        for feature in gb_obj.features:\n",
    "                            if feature.type == \"CDS\":\n",
    "                                if not 'pseudo' in feature.qualifiers:\n",
    "                                    prot_id = feature.qualifiers['locus_tag'][0]\n",
    "                                    translation = feature.qualifiers['translation'][0]\n",
    "                                    if 'product' in feature.qualifiers:\n",
    "                                        product = feature.qualifiers['product'][0]\n",
    "                                    else:\n",
    "                                        product = ''\n",
    "                                    genome_to_proteins_dict = {'id': prot_id, 'genome': genome_name, 'sequence': str(translation), 'product': product, 'type' : 'protein', 'protein number': protein_number}\n",
    "                                    genome_to_proteins.append(genome_to_proteins_dict)\n",
    "                                    protein_number +=1\n",
    "                            elif feature.type == \"rRNA\" or feature.type == \"tRNA\" or feature.type == \"tmRNA\":\n",
    "                                if feature.type == 'rRNA':\n",
    "                                    rRNA_count += 1\n",
    "                                elif feature.type == 'tRNA':\n",
    "                                    tRNA_count += 1 \n",
    "                                RNA_id = feature.qualifiers['locus_tag'][0]\n",
    "                                sequence = feature.extract(gb_obj).seq\n",
    "                                if 'product' in feature.qualifiers:\n",
    "                                    product = feature.qualifiers['product'][0]\n",
    "                                    genome_to_proteins_dict = {'id': RNA_id, 'genome': genome_name, 'sequence': str(sequence), 'product': product, 'type' : feature.type, 'protein number': '-'}\n",
    "                                    genome_to_proteins.append(genome_to_proteins_dict)\n",
    "                            if feature.type == \"source\":\n",
    "                                if 'plasmid' in feature.qualifiers:\n",
    "                                    plasmid_counter += 1\n",
    "                    gc_content = round(gc_fraction(seq_concat) *100, 2)\n",
    "                    for gb_obj in SeqIO.parse(genbank_file,'genbank'):\n",
    "                        tot += len(gb_obj.seq)\n",
    "                        if( n50 == 0 and tot > genome_length/2 ):\n",
    "                            n50 = len(gb_obj.seq)\n",
    "                    row_dict = {'Name': genome_name, 'Organism': organism, 'Strain': strain, 'Taxonomy id': tax_id, 'Length': genome_length, 'Contigs': count, 'Gene count': protein_number+tRNA_count+rRNA_count, 'Plasmids': plasmid_counter, 'GC%': gc_content, 'N50': n50, 'tRNA': tRNA_count, 'rRNA': rRNA_count, 'protein count': protein_number}\n",
    "                    dict_list.append(row_dict)\n",
    "\n",
    "            fasta_names=glob(f'{project_folder}/*.f*')\n",
    "            for fasta_file in fasta_names:\n",
    "                genome_name = os.path.basename(fasta_file).split('.f')[0]\n",
    "                if not genome_name in sequence_df.value.index.tolist():\n",
    "                    loading.name = f\"Running Prodigal for {genome_name}...\"\n",
    "                    subprocess.run(f\"prodigal -i {os.path.basename(fasta_file)} -q -a proteins.faa\", shell=True)\n",
    "                    loading.name = f\"Running barrnap for {genome_name}...\"\n",
    "                    subprocess.run(f\" barrnap {os.path.basename(fasta_file)} -q --threads {num_cpus} --outseq rRNA.fasta\", shell=True)\n",
    "                    loading.name = f\"Running aragorn for {genome_name}...\"\n",
    "                    subprocess.run(f\"aragorn -l -gc11 -fo -o tRNA.fasta {os.path.basename(fasta_file)}\", shell=True)\n",
    "                    loading.name = \"Updating sequence statistic...\"\n",
    "                    genome_length = 0\n",
    "                    count = 0\n",
    "                    gene_count = 0\n",
    "                    plasmid_counter = '-'\n",
    "                    tot = 0\n",
    "                    n50 = 0\n",
    "                    rRNA_count = 0\n",
    "                    tRNA_count = 0\n",
    "                    protein_number = 0\n",
    "                    try:\n",
    "                        organism = name_df.at[genome_name, 'organism']\n",
    "                        strain = name_df.at[genome_name, 'strain']\n",
    "                        tax_id = name_df.at[genome_name, 'tax_id']\n",
    "                    except:\n",
    "                        organism = '-'\n",
    "                        strain = '-'\n",
    "                        tax_id = '-'\n",
    "                    seq_concat = \"\"\n",
    "                    for fa_obj in SeqIO.parse(fasta_file,'fasta'):\n",
    "                        genome_length += len(fa_obj.seq)\n",
    "                        count += 1\n",
    "                        seq_concat += fa_obj.seq\n",
    "                    gc_content = round(gc_fraction(seq_concat) *100, 2)\n",
    "                    for fa_obj in SeqIO.parse(fasta_file,'fasta'):\n",
    "                        tot += len(fa_obj.seq)\n",
    "                        if( n50 == 0 and tot > genome_length/2 ):\n",
    "                            n50 = len(fa_obj.seq)\n",
    "                    for prot_obj in SeqIO.parse(f\"{project_folder}/proteins.faa\",'fasta'):\n",
    "                        gene_count += 1\n",
    "                        genome_to_proteins_dict = {'id':  f'prot_{genome_name[-6:]}_{gene_count}', 'genome': genome_name, 'sequence': str(prot_obj.seq), 'product': '-', 'type': 'protein', 'protein number': protein_number}\n",
    "                        genome_to_proteins.append(genome_to_proteins_dict)\n",
    "                        protein_number +=1\n",
    "                    for rRNA_obj in SeqIO.parse(f\"{project_folder}/rRNA.fasta\",'fasta'):\n",
    "                        gene_count += 1\n",
    "                        rRNA_count +=1\n",
    "                        genome_to_proteins_dict = {'id': f'rRNA_{genome_name[-6:]}_{gene_count}', 'genome': genome_name, 'sequence': str(rRNA_obj.seq), 'product': rRNA_obj.id.split('::')[0].split('_')[0] + \" ribosomal RNA\", 'type': 'rRNA', 'protein number': '-'}\n",
    "                        genome_to_proteins.append(genome_to_proteins_dict)\n",
    "                    for tRNA_obj in SeqIO.parse(f\"{project_folder}/tRNA.fasta\",'fasta'):\n",
    "                        gene_count += 1\n",
    "                        type = 'tRNA'\n",
    "                        tRNA_count +=1\n",
    "                        if tRNA_obj.id == 'tmRNA':\n",
    "                            type = 'tmRNA'\n",
    "                            tRNA_count -= 1\n",
    "                        genome_to_proteins_dict = {'id': f'tRNA_{genome_name[-6:]}_{gene_count}', 'genome': genome_name, 'sequence': str(tRNA_obj.seq), 'product': tRNA_obj.id, 'type': type, 'protein number': '-'}\n",
    "                        genome_to_proteins.append(genome_to_proteins_dict)\n",
    "                    os.remove(\"proteins.faa\")\n",
    "                    os.remove(\"rRNA.fasta\")\n",
    "                    os.remove(\"tRNA.fasta\")\n",
    "                    os.remove(f\"{os.path.basename(fasta_file)}.fai\")\n",
    "                    row_dict = {'Name': genome_name, 'Organism': organism, 'Strain': strain, 'Taxonomy id': tax_id, 'Length': genome_length, 'Contigs': count, 'Gene count': protein_number+tRNA_count+rRNA_count, 'Plasmids': plasmid_counter, 'GC%': gc_content, 'N50': n50, 'tRNA': tRNA_count, 'rRNA': rRNA_count, 'protein count': protein_number}\n",
    "                    dict_list.append(row_dict)\n",
    "\n",
    "            df = pd.DataFrame.from_dict(dict_list)\n",
    "            if not df.empty:\n",
    "                df = pd.concat([sequence_df.value, df.set_index('Name')])\n",
    "                sequence_df.value=df\n",
    "                sequence_df.value.to_csv('sequence_stats.csv')\n",
    "            sequence_df.value = pd.read_csv('sequence_stats.csv', index_col=0)\n",
    "            genome_to_protein_add_df = pd.DataFrame.from_dict(genome_to_proteins)\n",
    "            if os.path.isfile(f\"{project_folder}/genome_to_protein.csv\") == True:\n",
    "                genome_to_protein_df = pd.read_csv('genome_to_protein.csv')\n",
    "            else:\n",
    "                genome_to_protein_df = pd.DataFrame()\n",
    "            genome_to_protein_df = pd.concat([genome_to_protein_df, genome_to_protein_add_df]).reset_index(drop=True)\n",
    "            genome_to_protein_df.to_csv('genome_to_protein.csv', index=False)\n",
    "\n",
    "            \n",
    "            genome_to_protein_df = pd.read_csv('genome_to_protein.csv')\n",
    "            print(genome_to_protein_df)\n",
    "            genome_to_protein_df.set_index('id', inplace=True)\n",
    "            duplicate_index = genome_to_protein_df.index[genome_to_protein_df.index.duplicated()]\n",
    "            print(duplicate_index)\n",
    "            genome_to_protein_df.reset_index(inplace=True)\n",
    "            if not len(duplicate_index)==0:\n",
    "                genome_to_protein_df['sequence'] = genome_to_protein_df.groupby('id')['sequence'].transform(lambda x: ''.join(x))\n",
    "                genome_to_protein_df.drop_duplicates(subset='id', inplace=True)\n",
    "                print(genome_to_protein_df)\n",
    "            genome_to_protein_df.to_csv('genome_to_protein.csv', index=False)\n",
    "\n",
    "            \n",
    "            fig = make_subplots(rows=1, cols=3)\n",
    "            columns_to_plot = ['Length', 'Gene count', 'GC%']\n",
    "            for i, col in enumerate(columns_to_plot, start=1):\n",
    "                fig.add_trace(go.Bar(x=sequence_df.value.index, y=sequence_df.value[col], name=col,  xaxis=f'x{i}', yaxis=f'y{i}'))\n",
    "            for i in range(1, len(columns_to_plot) + 1):\n",
    "                fig.update_layout(xaxis=dict(title='Genomes', tickangle=-90), xaxis2=dict(title='Genomes', tickangle=-90), xaxis3=dict(title='Genomes', tickangle=-90))\n",
    "            \n",
    "            fig.update_yaxes(title_text=\"Length in bp\", row=1, col=1)\n",
    "            fig.update_yaxes(title_text=\"Gene count\", row=1, col=2)\n",
    "            fig.update_yaxes(title_text=\"GC%\", row=1, col=3)    \n",
    "            \n",
    "            fig.update_layout(\n",
    "                title='Sequence Statistics',\n",
    "                xaxis_title='Genomes',\n",
    "                colorway=px.colors.qualitative.T10,\n",
    "                grid={'rows': 1, 'columns': len(columns_to_plot)},\n",
    "                height=400,\n",
    "                width=1200,\n",
    "            )\n",
    "            fig.write_image(\"images/sequence_stats.png\")\n",
    "            stats_fig.object = fig\n",
    "            stats_fig.visible = True\n",
    "            \n",
    "            \n",
    "            loading.value = False\n",
    "            loading.name = \"\"\n",
    "            \n",
    "\n",
    "        def search(event):\n",
    "            loading.visible = True\n",
    "            loading.value = True\n",
    "            loading.name = \"Searching NCBI database ...\"\n",
    "            taxon_file = taxon_input.value.lower().replace(\" \", \"_\")\n",
    "            try:\n",
    "                subprocess.run(f\"\"\"datasets summary genome taxon \"{taxon_input.value}\" --assembly-source genbank >  {taxon_file}.json\"\"\", shell=True)\n",
    "                num = subprocess.Popen(f\"\"\"jq '.total_count' {taxon_file}.json\"\"\", stdout=subprocess.PIPE, shell=True)\n",
    "                num = int(num.stdout.read().decode('ascii').strip())\n",
    "                num_of_genomes_str.object = f\"{num} genomes found.\"\n",
    "                subprocess.run(f\"cat {taxon_file}.json | jq -r '.reports[] | [.accession, .organism.organism_name, .organism.infraspecific_names.strain, .organism.tax_id]| @csv' | head -{num} > info_table.csv\", shell=True) \n",
    "                loading.name = \"Done. Please download the wanted amount of genomes\"\n",
    "            except:\n",
    "                num_of_genomes_str.object = \"No genomes found. Please check for potential spelling errors\"\n",
    "                loading.name = \"\"\n",
    "            loading.value = False\n",
    "            \n",
    "        def download(event):\n",
    "            loading.visible = True\n",
    "            loading.value = True\n",
    "            loading.name = \"Downloading genomes ...\"\n",
    "            taxon_file = taxon_input.value.lower().replace(\" \", \"_\")\n",
    "            subprocess.run(f\"cat {taxon_file}.json | jq -r '.reports[]| .accession' | head -{num_of_genomes_input.value} > accession_list.txt\", shell=True)\n",
    "            subprocess.run(f\"datasets download genome accession  --include gbff,genome --inputfile accession_list.txt --filename {taxon_file}.zip\", shell=True)\n",
    "            subprocess.run(f\"unzip {taxon_file}.zip -d {project_folder}\", shell=True)\n",
    "            genome_iterator = open('accession_list.txt', 'r')\n",
    "            genome_lines = genome_iterator.readlines()\n",
    "            for line in genome_lines:\n",
    "                genome_path = f\"{project_folder}/ncbi_dataset/data/{line.strip()}\"\n",
    "                os.chdir(genome_path)\n",
    "                genome_iterator = os.listdir(genome_path)\n",
    "                if len(genome_iterator) == 1:\n",
    "                    subprocess.run(f\"\"\"mv {genome_iterator[0]} {line.strip()}.fna\"\"\", shell=True)\n",
    "                    subprocess.run(f\"mv {line.strip()}.fna {project_folder}\", shell=True)\n",
    "                else:\n",
    "                    subprocess.run(f\"\"\"mv genomic.gbff {line.strip()}.gbff\"\"\", shell=True)\n",
    "                    subprocess.run(f\"mv {line.strip()}.gbff {project_folder}\", shell=True)\n",
    "            os.chdir(project_folder)\n",
    "            shutil.rmtree(\"ncbi_dataset\")     \n",
    "            os.remove(f\"{taxon_file}.zip\")\n",
    "            os.remove(\"accession_list.txt\")\n",
    "            os.remove(f\"{taxon_file}.json\")\n",
    "            os.remove(\"README.md\")\n",
    "            \n",
    "            update_df()\n",
    "            loading.value = False\n",
    "            loading.name = \"Done. Please upload your own genomes or continue to next stage.\"\n",
    "        \n",
    "        def save(event):\n",
    "            if genome_input.filename != None:\n",
    "                loading.value = True\n",
    "                loading.visible = True\n",
    "                loading.name = \"Uploading genomes ...\"\n",
    "                genome_input.save(genome_input.filename)\n",
    "                update_df()\n",
    "                loading.value = False\n",
    "                loading.name = \"Done. Please continue to next stage.\"\n",
    "\n",
    "        def remove(event):\n",
    "            genome_name = sequence_df.value.iloc[sequence_df.selection[0]].name\n",
    "            sequence_df.value = sequence_df.value.drop([genome_name])\n",
    "            sequence_df.value.to_csv('sequence_stats.csv')\n",
    "            genome_to_protein_df = pd.read_csv('genome_to_protein.csv')\n",
    "            genome_to_protein_df = genome_to_protein_df[genome_to_protein_df.genome != genome_name].reset_index(drop=True)\n",
    "            genome_to_protein_df.to_csv('genome_to_protein.csv', index=False)\n",
    "            os.remove(glob(f\"{project_folder}/{genome_name}.*\")[0])\n",
    "                \n",
    "        welcome_Str = pn.pane.Str(\"Welcome to PanLoki!\\nPlease create a new project...\",styles={'font-size': '12pt'})\n",
    "        project_name = pn.widgets.TextInput(name='Project Name:', placeholder='Enter project name ...', width=150)\n",
    "        project_path_input = pn.widgets.TextInput(name='Project Path:', placeholder=os.getcwd(), width=450)\n",
    "        create_proj_button = pn.widgets.Button(name='Create new project', button_type='primary')\n",
    "        or_Str = pn.pane.Str(\"\\n\\n... or open an existing project by entering the path to the project folder\",styles={'font-size': '12pt'})\n",
    "        open_proj_name = pn.widgets.TextInput(name='Project Path', placeholder='Enter path to existing project...', width=600)\n",
    "        open_proj_button  = pn.widgets.Button(name='Open existing project', button_type='primary')\n",
    "        \n",
    "        create_proj_button.on_click(create)\n",
    "        open_proj_button.on_click(open_proj)\n",
    "\n",
    "        \n",
    "        config = {\"headerControls\": {\"close\": \"remove\", \"maximize\": \"remove\", \"normalize\": \"remove\", \"minimize\": \"remove\", \"smallify\": \"remove\"}}\n",
    "        floatpanel = pn.layout.FloatPanel(pn.Column(welcome_Str,pn.Row(project_path_input, project_name, create_proj_button), or_Str, pn.Row(open_proj_name, open_proj_button)), name='Welcome', margin=20, config=config)\n",
    "\n",
    "        taxon_input = pn.widgets.TextInput(name='Fetch genomes from NCBI', placeholder='Enter taxon name here...')\n",
    "        search_button = pn.widgets.Button(name='Search', button_type='primary')\n",
    "        num_of_genomes_str = pn.pane.Str(\"\",styles={'font-size': '12pt'})\n",
    "        \n",
    "        num_of_genomes_input = pn.widgets.IntInput(name='Number of genomes', value=5, step=1, start=0)\n",
    "        download_button = pn.widgets.Button(name='Download', button_type='primary')\n",
    "        \n",
    "        genome_input = pn.widgets.FileInput(accept='.fasta, .gbff, .fna, .fa', multiple=True)\n",
    "        genome_save_button =pn.widgets.Button(name='Save', button_type='primary')\n",
    "        upload_str = pn.pane.Str(\"\\n\\nUpload genomes below. The maximum \\nfile size for uploading is 100 Mb.\\nAllowed formats: .gbff, .fa, .fna, .fasta\",styles={'font-size': '12pt'})\n",
    "        \n",
    "        sequence_df = pn.widgets.DataFrame(pd.DataFrame(),height=450, width=1000)\n",
    "        stats_fig = pn.pane.Plotly(visible=False)\n",
    "\n",
    "        remove_button = pn.widgets.Button(name='Remove Genome', width=150, button_type='primary')\n",
    "        remove_button.on_click(remove)\n",
    "        \n",
    "        \n",
    "        \n",
    "        search_button.on_click(search)\n",
    "        download_button.on_click(download)\n",
    "        genome_save_button.on_click(save)\n",
    "        \n",
    "        genome_interface = pn.Row( pn.Column(pn.Row(taxon_input, search_button),num_of_genomes_str, pn.Row(num_of_genomes_input, download_button), pn.Column(upload_str, pn.Row(genome_input, genome_save_button))), pn.Row(sequence_df, remove_button))\n",
    "        \n",
    "        loading = pn.indicators.LoadingSpinner(value=False, name='', visible = False)\n",
    "        \n",
    "        gspec_spinner = pn.GridSpec()\n",
    "        gspec_spinner[2,0:2] = loading\n",
    "        \n",
    "        gspec_genome = pn.GridSpec(height = 750)\n",
    "        gspec_genome[0:2,   0:4  ] = genome_interface\n",
    "        gspec_genome[3, 1:4] = pn.Column(stats_fig)\n",
    "        gspec_genome[4,   4] = gspec_spinner\n",
    "\n",
    "        if show_float == False:\n",
    "            update_df()\n",
    "\n",
    "        if show_float == True:\n",
    "            return pn.Column(floatpanel, gspec_genome)\n",
    "        else:\n",
    "            return pn.Column(gspec_genome)\n",
    "\n",
    "    def panel(self):\n",
    "        return pn.Row(self.view,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74543ee7-3b79-43a1-bb00-c0045d15ce5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDiamond\u001b[39;00m(\u001b[43mparam\u001b[49m\u001b[38;5;241m.\u001b[39mParameterized):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mview\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcluster\u001b[39m(event):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'param' is not defined"
     ]
    }
   ],
   "source": [
    "class Diamond(param.Parameterized):\n",
    "    def view(self):\n",
    "\n",
    "        def cluster(event):\n",
    "            loading.visible = True\n",
    "            loading.name = \"Diamond clustering ...\"\n",
    "            loading.value = True\n",
    "            proteins = []\n",
    "            rnas= []\n",
    "            rna_dict = defaultdict(list)\n",
    "            rna_list = []\n",
    "            for index, row in gene_df.value.iterrows():\n",
    "                if row['type'] == 'protein':\n",
    "                    protein = SeqRecord(Seq(row['sequence']), id=index, description='')\n",
    "                    proteins.append(protein)\n",
    "                else:\n",
    "                    rna = SeqRecord(Seq(row['sequence']), id=index, description='')\n",
    "                    rnas.append(rna)\n",
    "                    if row[\"type\"] == \"tRNA\" :\n",
    "                        rna_dict[row['product'].split('(')[0]].append(index)\n",
    "                    elif row[\"type\"] == \"rRNA\" :\n",
    "                        rna_dict[row['product'].split(' .')[0]].append(index)\n",
    "                    else:\n",
    "                        rna_dict['tmRNA'].append(index)\n",
    "            for key in rna_dict:\n",
    "                cluster = rna_dict[key]\n",
    "                genome_list = []\n",
    "                row_cluster_to_rna = {'Name': cluster[-1], 'genes': cluster, 'pangenome': '-'}\n",
    "                for rna in cluster:\n",
    "                    genome_list.append(genome_to_protein_df.loc[rna]['genome'])\n",
    "                row_cluster_to_rna['genomes']=genome_list\n",
    "                row_cluster_to_rna['genomes_set']= \"-\"\n",
    "                row_cluster_to_rna['type']=genome_to_protein_df.loc[cluster[-1]]['type']\n",
    "                rna_list.append(row_cluster_to_rna)\n",
    "            cluster_to_rna_df = pd.DataFrame.from_dict(rna_list)\n",
    "            cluster_to_rna_df.to_csv('cluster_to_rna.csv' ,index=False)            \n",
    "            outputfile_proteins=f'{project_folder}/clusters.fasta'\n",
    "            outputfile_rnas=f'{project_folder}/rnas.fasta'\n",
    "            SeqIO.write(proteins,outputfile_proteins,'fasta')\n",
    "            SeqIO.write(rnas,outputfile_rnas,'fasta')\n",
    "            subprocess.run('makeblastdb -in rnas.fasta -parse_seqids -out blastdb/rnagenes_db -dbtype nucl', shell=True)\n",
    "            subprocess.run(\"diamond makedb --in clusters.fasta -d clusterdb\",shell=True)\n",
    "            os.remove(\"clusters.fasta\")\n",
    "            os.remove(\"rnas.fasta\")\n",
    "            subprocess.run(f\"diamond cluster --db clusterdb --evalue 0.00001 --approx-id {approx_slider.value} --member-cover {member_slider.value} --out {project_folder}/clusters.txt --cluster-steps faster sensitive ultra-sensitive\",shell=True)\n",
    "            loading.name = \"Diamond reclustering ...\"\n",
    "            subprocess.run(f\"diamond recluster --db clusterdb --evalue 0.00001 --approx-id {approx_slider.value} --member-cover {member_slider.value} --clusters {project_folder}/clusters.txt --out {project_folder}/reclusters.txt --cluster-steps faster sensitive ultra-sensitive\" ,shell=True)\n",
    "            loading.value = False\n",
    "            loading.name = \"Done. Please continue to next stage.\"\n",
    "\n",
    "        def save_changes_protein_table(event):\n",
    "            loading.name = 'Saving changes.'\n",
    "            loading.value = True\n",
    "            gene_df.value.to_csv('genome_to_protein.csv')\n",
    "            gene_df.value = pd.read_csv('genome_to_protein.csv', index_col=0)\n",
    "            loading.name = 'Done. Please cluster proteins.'\n",
    "            loading.value = False\n",
    "        cluster_button = pn.widgets.Button(name='Cluster Proteins', button_type='primary')\n",
    "        approx_slider = pn.widgets.EditableFloatSlider(name='Approximate sequence identity threshold in %', fixed_start=0.0, fixed_end=100.0, step=0.5, value=50.0)\n",
    "        member_slider= pn.widgets.EditableFloatSlider(name='Coverage threshold of the cluster member sequence in %', fixed_start=0.0, fixed_end=100.0, step=0.5, value=50.0)\n",
    "        cluster_button.on_click(cluster)\n",
    "        cluster_interface = pn.Column(approx_slider, member_slider, cluster_button)\n",
    "        genome_to_protein_df = pd.read_csv('genome_to_protein.csv', index_col=0)\n",
    "        gene_df = pn.widgets.Tabulator(genome_to_protein_df , header_filters=True, pagination=\"remote\", widths={'id': '10%', 'genome': '15%', 'sequence': '40%', 'product': '25%', 'type':'10%'}, height=700, width=1000)\n",
    "        save_changes_button = pn.widgets.Button(name='Save changes', button_type='primary')\n",
    "        save_changes_button.on_click(save_changes_protein_table)\n",
    "\n",
    "        loading = pn.indicators.LoadingSpinner(value=False, name='Cluster the proteins with Diamond.', visible = True)\n",
    "        if os.path.isfile(f'{project_folder}/reclusters.txt') == True:\n",
    "            loading.name = \"Calculated Dimond clusters detected. This stage can be skipped.\"\n",
    "            loading.visible = True\n",
    "        gspec_spinner = pn.GridSpec()\n",
    "        gspec_spinner[2,0:2] = loading\n",
    "        \n",
    "        gspec_cluster = pn.GridSpec(height = 600)\n",
    "        gspec_cluster[0:4,   0:3  ] = pn.Row(pn.Column(gene_df, save_changes_button), cluster_interface) \n",
    "        gspec_cluster[4,   4] = gspec_spinner\n",
    "        \n",
    "        \n",
    "        return gspec_cluster\n",
    "    def panel(self):\n",
    "        return self.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3132c355-005b-4304-80fe-3b2c1f2ce28d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPan_computation\u001b[39;00m(\u001b[43mparam\u001b[49m\u001b[38;5;241m.\u001b[39mParameterized):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mview\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpan_comp\u001b[39m(event):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'param' is not defined"
     ]
    }
   ],
   "source": [
    "class Pan_computation(param.Parameterized):\n",
    "    def view(self):\n",
    "        def pan_comp(event):\n",
    "            loading.visible = True\n",
    "            loading.name = \"Calculating Pangenome Characteristics...\"\n",
    "            loading.value = True\n",
    "\n",
    "            cluster_df = pd.read_csv(f'{project_folder}/reclusters.txt', sep='\\t', header=None)\n",
    "            prot_lists= []\n",
    "            prot_old = ''\n",
    "            for index, row in cluster_df.iterrows():\n",
    "                prot = row[0]\n",
    "                if prot != prot_old:\n",
    "                    if index > 0:\n",
    "                        prot_list.append(prot_list.pop(prot_list.index(prot_old)))\n",
    "                        prot_lists.append(prot_list)\n",
    "                    prot_list = []\n",
    "                    prot_list.append(row[1])\n",
    "                else:\n",
    "                    prot_list.append(row[1])\n",
    "                prot_old = row[0]\n",
    "            prot_lists.append(prot_list)\n",
    "            genome_to_protein_df = pd.read_csv('genome_to_protein.csv', index_col=0)\n",
    "            cluster_to_rna_df = pd.read_csv('cluster_to_rna.csv', converters = {\"genes\": pd.eval, 'genomes': pd.eval})\n",
    "            for index, row in cluster_to_rna_df.iterrows():\n",
    "                cluster_to_rna_df.at[index, 'genomes_set'] = set(cluster_to_rna_df.loc[index]['genomes'])\n",
    "            cluster_to_protein_df = pd.DataFrame()\n",
    "            cluster_to_protein_dict = {}\n",
    "            cluster_to_protein_list = []\n",
    "            #cluster_list = []\n",
    "            for cluster in prot_lists:\n",
    "                #helper_list = []\n",
    "                genome_list = []\n",
    "                row_cluster_to_protein = {'Name': cluster[-1], 'genes': cluster, 'pangenome': '-'}\n",
    "                for protein in cluster:\n",
    "                    genome_list.append(genome_to_protein_df.loc[protein]['genome'])\n",
    "                    #helper_list.append(SeqRecord(Seq(genome_to_protein_df.loc[protein]['sequence']), id=protein, description=''))\n",
    "                row_cluster_to_protein['genomes']=genome_list\n",
    "                row_cluster_to_protein['genomes_set']=set(genome_list)\n",
    "                row_cluster_to_protein['type']=genome_to_protein_df.loc[cluster[-1]]['type']\n",
    "                #cluster_list.append(helper_list)\n",
    "                cluster_to_protein_list.append(row_cluster_to_protein)\n",
    "            #for index, row in cluster_to_rna_df.iterrows():\n",
    "                #helper_list = []\n",
    "                #for rna in row['genes']:\n",
    "                #    helper_list.append(SeqRecord(Seq(genome_to_protein_df.loc[rna]['sequence']), id=rna, description=''))\n",
    "                #cluster_list.append(helper_list)\n",
    "            cluster_to_protein_df = pd.DataFrame.from_dict(cluster_to_protein_list)\n",
    "            cluster_to_gene_df = pd.concat([cluster_to_protein_df, cluster_to_rna_df], axis=0).set_index(\"Name\")\n",
    "            \n",
    "            stats = open('sequence_stats.csv', 'r')\n",
    "            reader = csv.reader(stats)\n",
    "            next(reader, None)\n",
    "            genome_names = [] \n",
    "            for row in reader:\n",
    "                genome_names.append(row[0])\n",
    "            pan_df = pd.DataFrame(0, index=genome_names, columns=['Cloud','Shell','Soft-Core','Core']) \n",
    "            soft_core = round(len(genome_names)*0.95)\n",
    "            for index, row in cluster_to_gene_df.iterrows():\n",
    "                counter =  Counter(row['genomes']).items()\n",
    "                if len(counter)==1:\n",
    "                    for item, count in counter:\n",
    "                        pan_df.loc[item]['Cloud'] += count\n",
    "                        cluster_to_gene_df.at[index, 'pangenome'] = 'Cloud'\n",
    "                elif 1 < len(counter) < soft_core:\n",
    "                    for item, count in counter:\n",
    "                        pan_df.loc[item]['Shell'] += count\n",
    "                        cluster_to_gene_df.at[index, 'pangenome'] = 'Shell'\n",
    "                elif soft_core != len(genome_names) and soft_core <= len(counter) < len(genome_names):\n",
    "                    for item, count in counter:\n",
    "                        pan_df.loc[item]['Soft-Core'] += count\n",
    "                        cluster_to_gene_df.at[index, 'pangenome'] = 'Soft-Core'\n",
    "                elif len(counter) == len(genome_names):\n",
    "                    for item, count in counter:\n",
    "                        pan_df.loc[item]['Core'] += count\n",
    "                        cluster_to_gene_df.at[index, 'pangenome'] = 'Core'\n",
    "            pan_df.to_csv('pan.csv')\n",
    "            cluster_to_gene_df.to_csv('cluster_to_gene.csv')\n",
    "\n",
    "            add_genomes_set = set()\n",
    "            pan_core_size_df = pd.DataFrame(0, index=genome_names, columns=['Core','Pan']) \n",
    "            for genome in genome_names:\n",
    "                add_genomes_set.add(genome)\n",
    "                core_size = 0\n",
    "                pan_size = 0\n",
    "                for index, row in cluster_to_gene_df.iterrows():\n",
    "                    if add_genomes_set.issubset(row['genomes_set']):\n",
    "                        core_size += 1\n",
    "                    elif len(add_genomes_set.intersection(row['genomes_set'])) > 0:\n",
    "                        pan_size +=1\n",
    "                pan_core_size_df.loc[genome]['Core']= core_size\n",
    "                pan_core_size_df.loc[genome]['Pan']= pan_size+core_size\n",
    "            pan_core_size_df.to_csv('pan_core_size.csv')\n",
    "            show_pan_core()\n",
    "            loading.name = \"Done. Please continue to next stage.\"\n",
    "            loading.value = False\n",
    "\n",
    "        def show_pan_core():\n",
    "            pan_df = pd.read_csv('pan.csv', index_col=0)\n",
    "            traces = []\n",
    "            for col in pan_df.columns:\n",
    "                trace = go.Bar(x=pan_df.index, y=pan_df[col], name=col,  hoverinfo='y')\n",
    "                traces.append(trace)\n",
    "                \n",
    "            layout = go.Layout(\n",
    "                title='Pan Genome Distribution',\n",
    "                xaxis=dict(title='Genome'),\n",
    "                yaxis=dict(title='Cluster'),\n",
    "                barmode='stack',\n",
    "                xaxis_tickangle=-90,\n",
    "                colorway=px.colors.qualitative.T10,\n",
    "                width=1200,\n",
    "                height=500\n",
    "            )\n",
    "            \n",
    "            fig_pc = go.Figure(data=traces, layout=layout)\n",
    "            fig_pc.write_image(\"images/pan_core.png\")\n",
    "            pan_core_fig.object =fig_pc\n",
    "            pan_core_fig.visible = True\n",
    "\n",
    "            pan_core_size_df = pd.read_csv('pan_core_size.csv', index_col=0)\n",
    "            trace_core = go.Scatter(x=pan_core_size_df.index, y=pan_core_size_df['Core'], mode='lines+markers', name='Core', hoverinfo='y')\n",
    "            trace_pan = go.Scatter(x=pan_core_size_df.index, y=pan_core_size_df['Pan'], mode='lines+markers', name='Pan',  hoverinfo='y')\n",
    "            \n",
    "            layout = go.Layout(\n",
    "                title='Pan-Core Chart',\n",
    "                xaxis=dict(title='Genomes'),\n",
    "                yaxis=dict(title='Cluster'),\n",
    "                xaxis_tickangle=-90,\n",
    "                colorway=px.colors.qualitative.T10,\n",
    "                width=1200,\n",
    "                height=500\n",
    "            )\n",
    "            \n",
    "            fig_pcs = go.Figure(data=[trace_core, trace_pan], layout=layout)\n",
    "            fig_pcs.write_image(\"images/pan_core_size.png\")\n",
    "            pan_core_size_fig.object = fig_pcs\n",
    "            pan_core_size_fig.visible = True\n",
    "\n",
    "            \n",
    "        msa_hmm_button=pn.widgets.Button(name='Pangenome Charecteristics Calculation', button_type='primary')\n",
    "        msa_hmm_button.on_click(pan_comp)\n",
    "        \n",
    "        pan_core_fig = pn.pane.Plotly(visible=False)\n",
    "        pan_core_size_fig = pn.pane.Plotly(visible=False)\n",
    "\n",
    "        if os.path.isfile('pan_core_size.csv') and os.path.isfile('pan.csv'):\n",
    "            show_pan_core()\n",
    "\n",
    "        loading = pn.indicators.LoadingSpinner(value=False, name='', visible = False)\n",
    "\n",
    "        if os.path.exists(f\"{project_folder}/pan.csv\") == True and os.path.exists(f\"{project_folder}/pan_core_size.csv\") == True:\n",
    "            loading.visible = True\n",
    "            loading.name = 'Characteristics detected. This stage can be skipped.'\n",
    "            \n",
    "        \n",
    "        msa_interface = msa_hmm_button\n",
    "\n",
    "        \n",
    "        gspec_msa = pn.GridSpec(height = 600)\n",
    "        gspec_msa[0,   0  ] = msa_interface\n",
    "        gspec_msa[1:10, 0:7] = pn.Column(pan_core_fig,pan_core_size_fig)\n",
    "        gspec_msa[10,   7:10] = loading\n",
    "        \n",
    "        return gspec_msa\n",
    "    def panel(self):\n",
    "        return self.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f4a0a9-7745-479d-9c57-668253f72a44",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSequence_Workbench\u001b[39;00m(\u001b[43mparam\u001b[49m\u001b[38;5;241m.\u001b[39mParameterized):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mview\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m         cluster_to_protein_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_to_gene.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, converters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m\"\u001b[39m: pd\u001b[38;5;241m.\u001b[39meval})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'param' is not defined"
     ]
    }
   ],
   "source": [
    "class Sequence_Workbench(param.Parameterized):\n",
    "    def view(self):\n",
    "        cluster_to_protein_df = pd.read_csv('cluster_to_gene.csv', index_col=0, converters = {\"genes\": pd.eval})\n",
    "        genome_to_protein_df = pd.read_csv('genome_to_protein.csv', index_col=0)\n",
    "        cluster_overview_df = cluster_to_protein_df[['genes', 'type', 'pangenome']].copy().rename(columns={\"genes\": \"size\"})\n",
    "        cluster_overview_df['product'] = '-'\n",
    "        for index, row in cluster_overview_df.iterrows():\n",
    "            cluster_overview_df.at[index, 'size'] = len(row['size'])\n",
    "            product = ''\n",
    "            for protein in row['size']:\n",
    "                if protein in genome_to_protein_df.index:\n",
    "                    product = genome_to_protein_df.loc[protein]['product']\n",
    "                    break\n",
    "            cluster_overview_df.at[index, 'product'] = product\n",
    "        cluster_overview_df = cluster_overview_df.astype({'size': 'int64'})\n",
    "        nested_cluster_df = lambda row: pn.widgets.Tabulator(genome_to_protein_df.loc[cluster_to_protein_df.loc[row.name]['genes']], width=900, layout='fit_columns', widths={'id': '10%', 'genome': '15%', 'translation': '40%', 'product': '35%'})\n",
    "\n",
    "        seq_stats_df = pd.read_csv('sequence_stats.csv')\n",
    "        color_df = seq_stats_df['Name'].copy().to_frame()\n",
    "        color_df['Color'] = '-'\n",
    "        color_df['Color2'] = '-'\n",
    "        num_genomes = len(color_df.index)\n",
    "        colors = cm.rainbow(np.linspace(0, 1, num_genomes))\n",
    "        for index, row in color_df.iterrows():\n",
    "            color_df.at[index, 'Color'] ='#ff' + str(mplc.rgb2hex(colors[index])).rsplit('#')[1]\n",
    "            color_df.at[index, 'Color2'] = str(mplc.rgb2hex(colors[index]))\n",
    "        color_df.to_csv(\"color.csv\", index = False)\n",
    "        color_df = pd.read_csv('color.csv', index_col=0)\n",
    "\n",
    "        legend = pn.pane.Plotly(visible=True)\n",
    "        fig = px.bar(color_df, y=color_df.index, color='Color2', color_discrete_sequence=color_df['Color2'], orientation='h')\n",
    "        fig.update_layout(title='Genome Colors',\n",
    "                          showlegend=False,\n",
    "                          width=200, \n",
    "                          height=700)\n",
    "        legend.object = fig\n",
    "\n",
    "        def get_colors(seqs, protein):\n",
    "            \"\"\"make colors for bases in sequence\"\"\"\n",
    "            text = [i for s in list(seqs) for i in s]\n",
    "            if protein == True:\n",
    "                clrs =\t{'A': 'lightgreen', 'G': 'lightgreen', 'C': 'green', 'D': 'darkgreen', 'E': 'darkgreen', 'N': 'darkgreen', 'Q': 'darkgreen',\n",
    "                        'I': 'blue', 'L': 'blue', 'M': 'blue', 'V': 'blue', 'F': 'palevioletred', 'W': ' palevioletred', 'Y': ' palevioletred', 'H': 'darkblue', 'K': 'orange',\n",
    "                        'R': 'orange', 'P': 'pink', 'S': 'red', 'T': 'red', '-': 'white', 'X' : 'gray'}\n",
    "            else:\n",
    "                clrs =  {'A':'red','T':'green','G':'orange','C':'blue','-':'white', 'U': 'purple', 'N':'yellow', 'R':'yellow', 'Y':'yellow'}\n",
    "            colors = [clrs[i.upper()] for i in text]\n",
    "            return colors\n",
    "        \n",
    "        \n",
    "        def view_alignment(aln, protein_bool, fontsize=\"9pt\", plot_width=800):\n",
    "            \"\"\"Bokeh sequence alignment view\"\"\"\n",
    "        \n",
    "            #make sequence and id lists from the aln object\n",
    "            seqs = [rec.seq for rec in (aln)]\n",
    "            ids = [rec.id for rec in aln]    \n",
    "            text = [i for s in list(seqs) for i in s.upper()]\n",
    "            colors = get_colors(seqs, protein_bool)    \n",
    "            N = len(seqs[0])\n",
    "            S = len(seqs)    \n",
    "            width = .4\n",
    "        \n",
    "            x = np.arange(1,N+1)\n",
    "            y = np.arange(0,S,1)\n",
    "            #creates a 2D grid of coords from the 1D arrays\n",
    "            xx, yy = np.meshgrid(x, y)\n",
    "            #flattens the arrays\n",
    "            gx = xx.ravel()\n",
    "            gy = yy.flatten()\n",
    "            #use recty for rect coords with an offset\n",
    "            recty = gy+.5\n",
    "            h= 1/S\n",
    "            #now we can create the ColumnDataSource with all the arrays\n",
    "            source = ColumnDataSource(dict(x=gx, y=gy, recty=recty, text=text, colors=colors ))#colors=colors\n",
    "            plot_height = len(seqs)*15+50\n",
    "            x_range = Range1d(0,N+1, bounds='auto')\n",
    "            if N>100:\n",
    "                viewlen=100\n",
    "            else:\n",
    "                viewlen=N\n",
    "            #view_range is for the close up view\n",
    "            view_range = (0,viewlen)\n",
    "            tools=\"xpan, xwheel_zoom, reset, save\"\n",
    "        \n",
    "            #entire sequence view (no text, with zoom)\n",
    "            p = figure(title=None,  height=50, width=plot_width,   #plot_width= plot_width,\n",
    "                       x_range=x_range, y_range=(0,S), tools=tools,\n",
    "                       min_border=0, toolbar_location='below')\n",
    "            rects = Rect(x=\"x\", y=\"recty\",  width=1, height=1, fill_color=\"colors\",\n",
    "                         line_color=None, fill_alpha=0.6)\n",
    "            p.add_glyph(source, rects)\n",
    "            p.yaxis.visible = False\n",
    "            p.grid.visible = False  \n",
    "        \n",
    "            #sequence text view with ability to scroll along x axis\n",
    "            p1 = figure(title=None, width=plot_width, height=plot_height,\n",
    "                        x_range=view_range, y_range=ids, tools=\"xpan,reset\",\n",
    "                        min_border=0, toolbar_location='below')#, lod_factor=1)          \n",
    "            glyph = Text(x=\"x\", y=\"y\", text=\"text\", text_align='center',text_color=\"black\", text_font_size=fontsize)\n",
    "            rects = Rect(x=\"x\", y=\"recty\",  width=1, height=1, fill_color=\"colors\",\n",
    "                        line_color=None, fill_alpha=0.4)\n",
    "            p1.add_glyph(source, glyph)\n",
    "            p1.add_glyph(source, rects)\n",
    "        \n",
    "            p1.grid.visible = False\n",
    "            p1.xaxis.major_label_text_font_style = \"bold\"\n",
    "            p1.yaxis.minor_tick_line_width = 0\n",
    "            p1.yaxis.major_tick_line_width = 0\n",
    "        \n",
    "            p = gridplot([[p],[p1]], toolbar_location='below')\n",
    "            return p\n",
    "        \n",
    "        \n",
    "        def alignment_view(event):\n",
    "            cluster_name = cluster_overview.value.iloc[cluster_overview.selection].index.to_list()[0]\n",
    "            if cluster_overview.value.loc[cluster_name]['size'] >= 2:\n",
    "                protein_bool = True\n",
    "                if cluster_overview.value.loc[cluster_name]['type'] != 'protein':\n",
    "                    protein_bool = False\n",
    "                cluster = []\n",
    "                loading.name = \"Generating MSA ...\"\n",
    "                loading.value = True\n",
    "                loading.visible = True\n",
    "                for gene in cluster_to_protein_df.loc[cluster_name]['genes']:\n",
    "                    cluster.append(SeqRecord(Seq(genome_to_protein_df.loc[gene]['sequence']), id=gene, description=''))\n",
    "                out_handle = StringIO()\n",
    "                SeqIO.write(cluster, out_handle, \"fasta\")\n",
    "                fasta_data = out_handle.getvalue()\n",
    "                mafft = subprocess.Popen([\"mafft\", \"--auto\", \"--thread\", \"-1\", \"-\"], stdout=subprocess.PIPE, stdin=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "                stdout_data, stderr_data = mafft.communicate(input=fasta_data)\n",
    "                output_file = f'{mafft_folder}/{cluster[-1].id}.fasta'\n",
    "                with open(output_file, 'w') as output_handle:\n",
    "                    output_handle.write(stdout_data)\n",
    "                aln = AlignIO.read(f\"{mafft_folder}/{cluster_name}.fasta\",'fasta')\n",
    "                alignment_viewer = view_alignment(aln=aln, protein_bool=protein_bool ,plot_width=1500)\n",
    "                alignment_viewer_bokeh.object = alignment_viewer\n",
    "                loading.value = False\n",
    "                loading.visible = False\n",
    "            else:\n",
    "                str_tree_explanation.object = 'The cluster needs to be at least of size two to display an alignment.'\n",
    "\n",
    "        tree_view = pn.pane.HTML(\"\"\"\n",
    "        <iframe src=\"https://phylogenetictreedraw.web.app/?hide=true\" id=\"myFrame\" height=\"600\" width=\"850\" allow_embedding=True>\n",
    "        </iframe>\"\"\",\n",
    "        styles={'background-color': '#F6F6F6',\n",
    "        'border': '2px solid black',\n",
    "        'border-radius': '5px',\n",
    "        'padding': '10px'})\n",
    "\n",
    "        html_helper = pn.pane.HTML(\" \")\n",
    "\n",
    "        def is_valid(input_string):\n",
    "            elements = input_string.split(',')\n",
    "            for element in elements:\n",
    "                num_part = element.split(':')[1].split(')')[0]\n",
    "                if num_part != '0.0':\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        def insert_value_after_identifier(string):\n",
    "            pattern = r'\\b[A-Za-z][A-Za-z0-9_.\\[\\]]+(?=:)'\n",
    "            matches = re.findall(pattern, string)\n",
    "            for match in matches:\n",
    "                string = string.replace(match, f\"{match}[{color_df.loc[genome_to_protein_df.loc[match]['genome']]['Color']}]\")\n",
    "            return string\n",
    "        \n",
    "        def get_tree(event):\n",
    "            cluster_name = cluster_overview.value.iloc[cluster_overview.selection].index.to_list()[0]\n",
    "            if os.path.exists(f\"{mafft_folder}/{cluster_name}.fasta\") == True:\n",
    "                loading.name = \"Generating Tree ...\"\n",
    "                loading.value = True\n",
    "                loading.visible = True\n",
    "                if cluster_overview.value.loc[cluster_name]['size'] >= 2:\n",
    "                    if cluster_overview.value.loc[cluster_name]['type'] == 'protein':\n",
    "                        subprocess.run(f\"fasttree < {mafft_folder}/{cluster_name}.fasta >  {tree_folder}/{cluster_name}.tre\",shell=True)\n",
    "                    else:\n",
    "                        subprocess.run(f\"fasttree -gtr -nt < {mafft_folder}/{cluster_name}.fasta >  {tree_folder}/{cluster_name}.tre\",shell=True)\n",
    "                    with open(f'{tree_folder}/{cluster_name}.tre', 'r') as f:\n",
    "                        data = f.read()\n",
    "                    data = data[0:-1]\n",
    "                    if is_valid(data) == True:\n",
    "                        html_helper.object = f\"\"\"<script type=\"text/javascript\">\n",
    "                        var panel_row_elements = document.getElementsByClassName('bk-panel-models-layout-Column');\n",
    "                        console.log(panel_row_elements);\n",
    "                        var htmlElements = panel_row_elements[0].shadowRoot.childNodes[10].shadowRoot.childNodes[9].shadowRoot.childNodes[12];\n",
    "                        console.log(htmlElements);\n",
    "                        var myFrame = htmlElements.shadowRoot.childNodes[9].shadowRoot.childNodes[8].childNodes[0];\n",
    "                        console.log(myFrame);\n",
    "                        myFrame.contentWindow.postMessage(`{insert_value_after_identifier(data)}`, '*');\n",
    "                        </script>\"\"\"\n",
    "                        html_helper.param.trigger('object')\n",
    "                        loading.value = False\n",
    "                        loading.visible = False\n",
    "                    else:\n",
    "                        str_tree_explanation.object = 'The sequences are identical. It is not possible to draw a tree.'\n",
    "                else:\n",
    "                    str_tree_explanation.object = 'The cluster needs to be at least of size two to display a tree.'\n",
    "            else:\n",
    "                str_tree_explanation.object = 'Please generate the MSA before you draw the tree.'\n",
    "        \n",
    "        draw_tree_button = pn.widgets.Button(name='Draw Tree', width=150, button_type='primary')\n",
    "        draw_tree_button.on_click(get_tree)\n",
    "        \n",
    "        str_tree_explanation = pn.pane.Str(\n",
    "            'Please select a cluster in the table \\non the left and use \"Show MSA\" first \\nand \"Draw Tree\" or \"Copy MSA to clipboar\" second.',\n",
    "            styles={'font-size': '12pt'}\n",
    "        )\n",
    "                    \n",
    "        alignment_viewer_bokeh = pn.pane.Bokeh()\n",
    "\n",
    "        def copy_to_clipboard(event):\n",
    "            cluster_name = cluster_overview.value.iloc[cluster_overview.selection].index.to_list()[0]\n",
    "            if os.path.exists(f\"{mafft_folder}/{cluster_name}.fasta\") == True:\n",
    "                if cluster_overview.value.loc[cluster_name]['size'] >= 2: \n",
    "                    with open(f'{mafft_folder}/{cluster_name}.fasta', 'r') as f:\n",
    "                        data = f.read()\n",
    "                    pc.copy(data) \n",
    "                else:\n",
    "                    str_tree_explanation.object = 'The cluster needs to be at least of size two to copy the alignment.'\n",
    "            else:\n",
    "                str_tree_explanation.object = 'Please generate the MSA before you draw the tree.'\n",
    "        \n",
    "        copy_button = pn.widgets.Button(name='Copy MSA to clipboard', width=150, button_type='primary')\n",
    "        copy_button.on_click(copy_to_clipboard)\n",
    "        \n",
    "        \n",
    "        cluster_overview = pn.widgets.Tabulator(cluster_overview_df, header_filters=True, pagination='remote', row_content=nested_cluster_df, height = 700, width=900, layout= 'fit_columns')\n",
    "        alignment_button = pn.widgets.Button(name='Show MSA', button_type='primary')\n",
    "        loading = pn.indicators.LoadingSpinner(value=False, name='', visible = False, size = 50)\n",
    "\n",
    "        alignment_button.on_click(alignment_view)\n",
    "\n",
    "        workspace_interface = pn.Column(html_helper, pn.Row(cluster_overview, pn.Column(alignment_button,draw_tree_button, copy_button, str_tree_explanation, loading)), pn.Row(tree_view, legend), alignment_viewer_bokeh )\n",
    "                \n",
    "        return workspace_interface\n",
    "    def panel(self):\n",
    "        return self.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28092a4b-6db5-464c-a04a-a5ed97d70392",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1874445932.py, line 105)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 105\u001b[0;36m\u001b[0m\n\u001b[0;31m    sequence_tabulator.value.\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Blast(param.Parameterized):\n",
    "    def view(self):\n",
    "        def get_colors(seqs, protein):\n",
    "            \"\"\"make colors for bases in sequence\"\"\"\n",
    "            text = [i for s in list(seqs) for i in s]\n",
    "            if protein == True:\n",
    "                clrs =\t{'A': 'lightgreen', 'G': 'lightgreen', 'C': 'green', 'D': 'darkgreen', 'E': 'darkgreen', 'N': 'darkgreen', 'Q': 'darkgreen',\n",
    "                        'I': 'blue', 'L': 'blue', 'M': 'blue', 'V': 'blue', 'F': 'palevioletred', 'W': ' palevioletred', 'Y': ' palevioletred', 'H': 'darkblue', 'K': 'orange',\n",
    "                        'R': 'orange', 'P': 'pink', 'S': 'red', 'T': 'red', '-': 'white', 'X' : 'gray'}\n",
    "            else:\n",
    "                clrs =  {'A':'red','T':'green','G':'orange','C':'blue','-':'white', 'U': 'purple', 'N':'yellow', 'R':'yellow', 'Y':'yellow'}\n",
    "            colors = [clrs[i.upper()] for i in text]\n",
    "            return colors\n",
    "        \n",
    "        \n",
    "        def view_alignment(aln, protein_bool, fontsize=\"9pt\", plot_width=800):\n",
    "            \"\"\"Bokeh sequence alignment view\"\"\"\n",
    "        \n",
    "            #make sequence and id lists from the aln object\n",
    "            seqs = [rec.seq for rec in (aln)]\n",
    "            ids = [rec.id for rec in aln]    \n",
    "            text = [i for s in list(seqs) for i in s.upper()]\n",
    "            colors = get_colors(seqs, protein_bool)    \n",
    "            N = len(seqs[0])\n",
    "            S = len(seqs)    \n",
    "            width = .4\n",
    "        \n",
    "            x = np.arange(1,N+1)\n",
    "            y = np.arange(0,S,1)\n",
    "            #creates a 2D grid of coords from the 1D arrays\n",
    "            xx, yy = np.meshgrid(x, y)\n",
    "            #flattens the arrays\n",
    "            gx = xx.ravel()\n",
    "            gy = yy.flatten()\n",
    "            #use recty for rect coords with an offset\n",
    "            recty = gy+.5\n",
    "            h= 1/S\n",
    "            #now we can create the ColumnDataSource with all the arrays\n",
    "            source = ColumnDataSource(dict(x=gx, y=gy, recty=recty, text=text, colors=colors ))#colors=colors\n",
    "            plot_height = len(seqs)*15+50\n",
    "            x_range = Range1d(0,N+1, bounds='auto')\n",
    "            if N>100:\n",
    "                viewlen=100\n",
    "            else:\n",
    "                viewlen=N\n",
    "            #view_range is for the close up view\n",
    "            view_range = (0,viewlen)\n",
    "            tools=\"xpan, xwheel_zoom, reset, save\"\n",
    "        \n",
    "            #entire sequence view (no text, with zoom)\n",
    "            p = figure(title=None,  height=50, width=plot_width,   #plot_width= plot_width,\n",
    "                       x_range=x_range, y_range=(0,S), tools=tools,\n",
    "                       min_border=0, toolbar_location='below')\n",
    "            rects = Rect(x=\"x\", y=\"recty\",  width=1, height=1, fill_color=\"colors\",\n",
    "                         line_color=None, fill_alpha=0.6)\n",
    "            p.add_glyph(source, rects)\n",
    "            p.yaxis.visible = False\n",
    "            p.grid.visible = False  \n",
    "        \n",
    "            #sequence text view with ability to scroll along x axis\n",
    "            p1 = figure(title=None, width=plot_width, height=plot_height,\n",
    "                        x_range=view_range, y_range=ids, tools=\"xpan,reset\",\n",
    "                        min_border=0, toolbar_location='below')#, lod_factor=1)          \n",
    "            glyph = Text(x=\"x\", y=\"y\", text=\"text\", text_align='center',text_color=\"black\", text_font_size=fontsize)\n",
    "            rects = Rect(x=\"x\", y=\"recty\",  width=1, height=1, fill_color=\"colors\",\n",
    "                        line_color=None, fill_alpha=0.4)\n",
    "            p1.add_glyph(source, glyph)\n",
    "            p1.add_glyph(source, rects)\n",
    "        \n",
    "            p1.grid.visible = False\n",
    "            p1.xaxis.major_label_text_font_style = \"bold\"\n",
    "            p1.yaxis.minor_tick_line_width = 0\n",
    "            p1.yaxis.major_tick_line_width = 0\n",
    "        \n",
    "            p = gridplot([[p],[p1]], toolbar_location='below')\n",
    "            return p\n",
    "        \n",
    "        def blastp(event):\n",
    "            blastmode = 'blastp'\n",
    "            if blast_switch.value == True:\n",
    "                blastmode = 'blastx'\n",
    "            with open(\"query.fasta\", \"w\") as output_handle:\n",
    "                SeqIO.write(SeqRecord(Seq(seq_input.value), id=id_input.value, description=''), output_handle, \"fasta\")\n",
    "            subprocess.run(f\"diamond {blastmode} -d clusterdb -q query.fasta -o {blast_folder}/{id_input.value}.tsv\",shell=True)\n",
    "            os.remove('query.fasta')\n",
    "            results_df = pd.read_csv(f\"{blast_folder}/{id_input.value}.tsv\", sep='\\t', index_col=1, names=['Query accession', 'Target accession', 'Sequence identity', 'Length', 'Mismatches', 'Gap openings', 'Query start', 'Query end', 'Target start', 'Target end', \"E-value\", \"Bit score\"])\n",
    "            results_tabulator.value = results_df\n",
    "            protein_df = pd.read_csv('genome_to_protein.csv', index_col=0)\n",
    "            cluster_df = pd.read_csv('cluster_to_gene.csv', index_col=0)\n",
    "            recluster_df = pd.read_csv('reclusters.txt', sep='\\t', index_col=0, names=['Cluster', 'Protein'])\n",
    "            matching_sequence_list = []\n",
    "            if not results_df.empty:\n",
    "                align = []\n",
    "                if blast_switch.value == False: \n",
    "                    align.append(SeqRecord(Seq(seq_input.value), id=id_input.value, description=''))\n",
    "                for index, row in results_df.iterrows():\n",
    "                    cluster = recluster_df.index[recluster_df['Protein'] == index].tolist()[0]\n",
    "                    sequence = protein_df.loc[index]['sequence']\n",
    "                    matching_sequence_row = {'Name': index, 'Cluster': cluster, 'Pangenome': cluster_df.loc[cluster]['pangenome'],'Sequence': sequence, 'Product': protein_df.loc[index]['product'], 'Type': protein_df.loc[index]['type'], }\n",
    "                    matching_sequence_list.append(matching_sequence_row)\n",
    "                    align.append(SeqRecord(Seq(protein_df.loc[index]['sequence']), id=index, description=''))\n",
    "                matching_sequence_df = pd.DataFrame.from_dict(matching_sequence_list)\n",
    "                matching_sequence_df.set_index('Name', inplace=True)\n",
    "                sequence_tabulator.value = matching_sequence_df\n",
    "                sequence_tabulator.visible = True\n",
    "                out_handle = StringIO()\n",
    "                SeqIO.write(align, out_handle, \"fasta\")\n",
    "                fasta_data = out_handle.getvalue()\n",
    "                mafft = subprocess.Popen([\"mafft\", \"--auto\", \"--thread\", \"-1\", \"-\"], stdout=subprocess.PIPE, stdin=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "                stdout_data, stderr_data = mafft.communicate(input=fasta_data)\n",
    "                output_file = f'{blast_folder}/{id_input.value}_alignment.fasta'\n",
    "                with open(output_file, 'w') as output_handle:\n",
    "                        output_handle.write(stdout_data)\n",
    "                protein_bool = True\n",
    "                aln = AlignIO.read(output_file,'fasta')\n",
    "                alignment_viewer = view_alignment(aln=aln, protein_bool=protein_bool ,plot_width=1600)\n",
    "                alignment_viewer_bokeh.object = alignment_viewer\n",
    "\n",
    "        def blastn(event):\n",
    "            with open(\"query.fasta\", \"w\") as output_handle:\n",
    "                SeqIO.write(SeqRecord(Seq(seq_input_rna.value), id=id_input_rna.value, description=''), output_handle, \"fasta\")\n",
    "            subprocess.run(f\"blastn -db blastdb/rnagenes_db -query query.fasta -num_threads {num_cpus} -mt_mode 0 -outfmt 0 -out {blast_folder}/{id_input_rna.value}_res\",shell=True)\n",
    "            subprocess.run(f\"blastn -db blastdb/rnagenes_db -query query.fasta -num_threads {num_cpus} -mt_mode 0 -outfmt 6 -out {blast_folder}/{id_input_rna.value}.tsv\",shell=True)\n",
    "            os.remove('query.fasta')\n",
    "            results_df = pd.read_csv(f\"{blast_folder}/{id_input_rna.value}.tsv\", sep='\\t', index_col=1, names=['Query accession', 'Target accession', 'Sequence identity', 'Length', 'Mismatches', 'Gap openings', 'Query start', 'Query end', 'Target start', 'Target end', \"E-value\", \"Bit score\"])\n",
    "            results_tabulator.value = results_df\n",
    "            protein_df = pd.read_csv('genome_to_protein.csv', index_col=0)\n",
    "            cluster_df = pd.read_csv('cluster_to_gene.csv', index_col=0)\n",
    "            matching_sequence_list = []\n",
    "            if not results_df.empty:\n",
    "                results_df.reset_index(inplace=True)\n",
    "                results_df.drop_duplicates(subset='Target accession', inplace=True)\n",
    "                results_df.set_index('Target accession', inplace=True)\n",
    "                align = []\n",
    "                align.append(SeqRecord(Seq(seq_input_rna.value), id=id_input_rna.value, description=''))\n",
    "                for index, row in results_df.iterrows():\n",
    "                    cluster = cluster_df.index[cluster_df['genes'].apply(lambda x: index in x)].tolist()[0]\n",
    "                    sequence = protein_df.loc[index]['sequence']\n",
    "                    matching_sequence_row = {'Name': index, 'Cluster': cluster, 'Pangenome': cluster_df.loc[cluster]['pangenome'],'Sequence': sequence, 'Product': protein_df.loc[index]['product'], 'Type': protein_df.loc[index]['type'], }\n",
    "                    matching_sequence_list.append(matching_sequence_row)\n",
    "                    align.append(SeqRecord(Seq(protein_df.loc[index]['sequence']), id=index, description=''))\n",
    "                matching_sequence_df = pd.DataFrame.from_dict(matching_sequence_list)\n",
    "                matching_sequence_df.set_index('Name', inplace=True)\n",
    "                sequence_tabulator.value = matching_sequence_df\n",
    "                sequence_tabulator.visible = True\n",
    "                out_handle = StringIO()\n",
    "                SeqIO.write(align, out_handle, \"fasta\")\n",
    "                fasta_data = out_handle.getvalue()\n",
    "                mafft = subprocess.Popen([\"mafft\", \"--auto\", \"--thread\", \"-1\", \"-\"], stdout=subprocess.PIPE, stdin=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "                stdout_data, stderr_data = mafft.communicate(input=fasta_data)\n",
    "                output_file = f'{blast_folder}/{id_input_rna.value}_alignment.fasta'\n",
    "                with open(output_file, 'w') as output_handle:\n",
    "                        output_handle.write(stdout_data)\n",
    "                aln = AlignIO.read(output_file,'fasta')\n",
    "                protein_bool = False\n",
    "                alignment_viewer = view_alignment(aln=aln, protein_bool=protein_bool ,plot_width=1600)\n",
    "                alignment_viewer_bokeh.object = alignment_viewer\n",
    "\n",
    "        diamond_blast_str = pn.pane.Str(\n",
    "            'Blast on protein database:',\n",
    "            styles={'font-size': '12pt'}\n",
    "        )\n",
    "        id_input = pn.widgets.TextInput(name='Name of query', placeholder='Enter an identifier for you blast search...')\n",
    "        seq_input = pn.widgets.TextInput(name='Sequence', placeholder='Enter Sequence...')\n",
    "        blast_switch = pn.widgets.Switch(name='Switch')\n",
    "        protein_text = pn.widgets.StaticText(value='Amino acids')\n",
    "        nucleic_text = pn.widgets.StaticText(value='Nucleic acids')\n",
    "        \n",
    "        rna_blast_str = pn.pane.Str(\n",
    "            'Blast on RNA encoding gene database:',\n",
    "            styles={'font-size': '12pt'}\n",
    "        )\n",
    "        blast_button = pn.widgets.Button(name='Diamond BLAST on proteins', button_type='primary')\n",
    "        blast_button.on_click(blastp)\n",
    "\n",
    "        id_input_rna = pn.widgets.TextInput(name='Name of query', placeholder='Enter an identifier for you blast search...')\n",
    "        seq_input_rna = pn.widgets.TextInput(name='Sequence', placeholder='Enter Sequence...')\n",
    "        \n",
    "        blast_rna_button = pn.widgets.Button(name='\\n\\nBLAST on RNA genes', button_type='primary')\n",
    "        blast_rna_button.on_click(blastn)\n",
    "        \n",
    "        results_tabulator = pn.widgets.Tabulator()\n",
    "        sequence_tabulator = pn.widgets.Tabulator(pagination='remote', width=1600, visible=False, layout = \"fit_columns\")\n",
    "        alignment_viewer_bokeh = pn.pane.Bokeh()\n",
    "        \n",
    "        blast_interface = pn.Column(diamond_blast_str,pn.Row(id_input, seq_input, pn.Row(protein_text, blast_switch, nucleic_text), blast_button), rna_blast_str, pn.Row(id_input_rna,seq_input_rna,blast_rna_button), results_tabulator, alignment_viewer_bokeh ,sequence_tabulator)\n",
    "        return blast_interface\n",
    "    def panel(self):\n",
    "        return self.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d21dd8-a97c-4b07-bfb3-5ba6bf8aeef6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGene_atlas\u001b[39;00m(\u001b[43mparam\u001b[49m\u001b[38;5;241m.\u001b[39mParameterized):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mview\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m         sequence_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence_stats.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'param' is not defined"
     ]
    }
   ],
   "source": [
    "class Gene_atlas(param.Parameterized):\n",
    "    def view(self):\n",
    "        sequence_df = pd.read_csv('sequence_stats.csv', index_col=0)\n",
    "        gene_df = pd.read_csv('genome_to_protein.csv', index_col=0)\n",
    "        cluster_df = pd.read_csv('cluster_to_gene.csv', index_col=0, converters = {'genes': pd.eval})\n",
    "        recluster_df = pd.read_csv('reclusters.txt', sep='\\t', index_col=0, names=['Cluster', 'Protein'])\n",
    "        \n",
    "        cluster_overview_df = cluster_df[['genes', 'type', 'pangenome']].copy().rename(columns={\"genes\": \"size\"})\n",
    "        cluster_overview_df = cluster_overview_df.loc[cluster_overview_df['pangenome'] == 'Core']\n",
    "        cluster_overview_df['product'] = '-'\n",
    "        for index, row in cluster_overview_df.iterrows():\n",
    "            cluster_overview_df.at[index, 'size'] = len(row['size'])\n",
    "            product = ''\n",
    "            for protein in row['size']:\n",
    "                if protein in gene_df.index:\n",
    "                    product = gene_df.loc[protein]['product']\n",
    "                    break\n",
    "            cluster_overview_df.at[index, 'product'] = product\n",
    "        cluster_overview_df = cluster_overview_df.astype({'size': 'int64'})\n",
    "        nested_cluster_df = lambda row: pn.widgets.Tabulator(gene_df.loc[cluster_df.loc[row.name]['genes']], width=900, layout='fit_columns', widths={'id': '10%', 'genome': '15%', 'translation': '40%', 'product': '35%'})\n",
    "        \n",
    "        genome_select = []\n",
    "        \n",
    "        for index, row in sequence_df.iterrows():\n",
    "            genome_select.append(index)\n",
    "            \n",
    "        atlas_view = pn.pane.HTML(\"\"\"\n",
    "        <iframe src=\"https://geneatlas.web.app/\" id=\"myFrame\" height=\"900\" width=\"850\" allow_embedding=True>\n",
    "        </iframe>\n",
    "        \"\"\",\n",
    "        styles={'background-color': '#F6F6F6',\n",
    "        'border': '2px solid black',\n",
    "        'border-radius': '5px',\n",
    "        'padding': '10px'}, height=900)\n",
    "        html_helper = pn.pane.HTML(\" \")\n",
    "        \n",
    "        def send_atlas(event):\n",
    "            \n",
    "            genome_selection = genome_df.selection\n",
    "            reference_genome = select_ref.value\n",
    "            \n",
    "            if len(cluster_overview.selection) == 0:\n",
    "                select_warning_str.object = \"Select a starting gene set for the gene atlas below.\"                \n",
    "            else:\n",
    "                select_warning_str = pn.pane.Str(\n",
    "                    'It is recommended to only select up to 10 genomes \\naside the referennce genome for best visibility.\\nThe best results are optained, if the assembly\\nof the genome is complete and made up of one sequence.\\nSelect a gene set below. It will be\\ncoloured deep blue.',\n",
    "                    styles={'font-size': '12pt'})\n",
    "                loading.value = True\n",
    "                loading.visible = True\n",
    "                cluster_name = cluster_overview.value.iloc[cluster_overview.selection].index.to_list()[0]\n",
    "                cluster_numbers = []\n",
    "                for gene in cluster_df.loc[cluster_name]['genes']:\n",
    "                        cluster_numbers.append({gene_df.loc[gene]['genome'] : gene_df.loc[gene]['protein number']})\n",
    "                genome_dd = defaultdict(list)\n",
    "                for d in cluster_numbers:\n",
    "                    for key, value in d.items():\n",
    "                        genome_dd[key].append(value)\n",
    "                genome_dd = dict(genome_dd)\n",
    "                \n",
    "                genome_list = []\n",
    "                helper_list = []\n",
    "                if len(genome_selection) == 0:\n",
    "                    protein_position = genome_dd[reference_genome]\n",
    "                    protein_position.sort()\n",
    "                    genome_list.append({reference_genome: [int(sequence_df.loc[reference_genome]['protein count']), int(protein_position[0])]})\n",
    "                    helper_list.append(reference_genome)\n",
    "                else:\n",
    "                    for genome in genome_selection:\n",
    "                        id = genome_df.value.iloc[genome].name\n",
    "                        protein_position = genome_dd[id]\n",
    "                        protein_position.sort()\n",
    "                        genome_list.append({id: [int(sequence_df.loc[id]['protein count']), int(protein_position[0])]})\n",
    "                        helper_list.append(id)\n",
    "                    \n",
    "                    protein_position = genome_dd[reference_genome]\n",
    "                    protein_position.sort()\n",
    "                    if {reference_genome: [int(sequence_df.loc[reference_genome]['protein count']), int(protein_position[0])]} in genome_list:\n",
    "                        genome_list.append(genome_list.pop(genome_list.index({reference_genome: [int(sequence_df.loc[reference_genome]['protein count']), int(protein_position[0])]})))\n",
    "                        helper_list.append(helper_list.pop(helper_list.index(reference_genome)))\n",
    "                    else:\n",
    "                        genome_list.append({reference_genome: [int(sequence_df.loc[reference_genome]['protein count']), int(protein_position[0])]})\n",
    "                        helper_list.append(reference_genome)\n",
    "    \n",
    "                cluster_dict_list = []\n",
    "                for index, row in gene_df.loc[(gene_df['genome'] == reference_genome) & (gene_df['type'] == 'protein')].iterrows():\n",
    "                    cluster_dict  = defaultdict(list)\n",
    "                    cluster_index = recluster_df.loc[recluster_df['Protein']==index].index[0]\n",
    "                    gene_info = cluster_df.loc[cluster_index]['genes']\n",
    "                    for gene in gene_info:\n",
    "                        if gene_df.loc[gene]['genome'] in helper_list:\n",
    "                            cluster_dict[gene_df.loc[gene]['genome']].append(int(gene_df.loc[gene]['protein number']))\n",
    "                    cluster_dict_list.append(dict(cluster_dict))\n",
    "                atlas_json = {\"genomes\": genome_list, \"gensets\": cluster_dict_list}\n",
    "                atlas_json = json.dumps(atlas_json)\n",
    "                loading.value = False\n",
    "                loading.visible = False\n",
    "                html_helper.object = f\"\"\"<script type=\"text/javascript\">\n",
    "                var panel_row_elements = document.getElementsByClassName('bk-panel-models-layout-Column');\n",
    "                console.log(panel_row_elements);\n",
    "                var myFrame = panel_row_elements[0].shadowRoot.childNodes[10].shadowRoot.childNodes[9].shadowRoot.childNodes[9].shadowRoot.childNodes[9].shadowRoot.childNodes[8].childNodes[0];\n",
    "                console.log(myFrame);\n",
    "                myFrame.contentWindow.postMessage(`{atlas_json}`, '*');\n",
    "                </script>\"\"\"\n",
    "                html_helper.param.trigger('object')\n",
    "        \n",
    "        select_ref = pn.widgets.Select(name='Reference Genome', options=genome_select)\n",
    "        atlas_button = pn.widgets.Button(name='Draw Geneatlas', width=150, button_type='primary')\n",
    "        atlas_button.on_click(send_atlas)\n",
    "\n",
    "        genome_df = pn.widgets.Tabulator(sequence_df , header_filters=True, pagination=\"remote\", height=400, width=800, selectable=\"checkbox\")\n",
    "        select_warning_str = pn.pane.Str(\n",
    "            'It is recommended to only select up to 10 genomes \\naside the referennce genome for best visibility.\\nThe best results are optained, if the assembly\\nof the genome is complete and made up of one sequence.\\nSelect a gene set below. It will be\\ncoloured deep blue.',\n",
    "            styles={'font-size': '12pt'}\n",
    "        )\n",
    "        loading = pn.indicators.LoadingSpinner(value=False, name='Calculating Genealtas...' ,visible = False)\n",
    "        gspec_spinner = pn.GridSpec()\n",
    "        gspec_spinner[2,0:2] = loading\n",
    "\n",
    "        cluster_overview = pn.widgets.Tabulator(cluster_overview_df, header_filters=True, pagination='remote', row_content=nested_cluster_df, height = 700, width=800, layout= 'fit_columns', selectable=\"checkbox-single\")\n",
    "\n",
    "        \n",
    "        gspec_atlas = pn.GridSpec(height = 1200)\n",
    "        gspec_atlas[0:4,   0:3  ] = pn.Row(atlas_view, pn.Column(select_ref ,atlas_button, html_helper, select_warning_str, genome_df, cluster_overview))\n",
    "        gspec_atlas[4,   0] = gspec_spinner\n",
    "        \n",
    "        \n",
    "        return gspec_atlas\n",
    "    def panel(self):\n",
    "        return self.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75734baf-3b1a-4c4b-88a9-b6b385948a66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mExport\u001b[39;00m(\u001b[43mparam\u001b[49m\u001b[38;5;241m.\u001b[39mParameterized):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mview\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSELECT\u001b[39;00m(Enum):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'param' is not defined"
     ]
    }
   ],
   "source": [
    "class Export(param.Parameterized):\n",
    "    \n",
    "    def view(self):\n",
    "        \n",
    "        class SELECT(Enum):\n",
    "            GENOMES = 1\n",
    "            CLUSTERS = 2\n",
    "            GENES = 3\n",
    "       \n",
    "        def display(event):\n",
    "            global enum\n",
    "            if select_export.value == \"Genomes\":\n",
    "                df = pd.read_csv('sequence_stats.csv', index_col=0)\n",
    "                enum = SELECT.GENOMES\n",
    "            elif select_export.value == \"Clusters\":\n",
    "                cluster_to_protein_df = pd.read_csv('cluster_to_gene.csv', index_col=0, converters = {\"genes\": pd.eval})\n",
    "                df = cluster_to_protein_df[['genes', 'type', 'pangenome']].copy()\n",
    "                enum = SELECT.CLUSTERS\n",
    "            else:\n",
    "                df = pd.read_csv('genome_to_protein.csv', index_col=0)\n",
    "                enum = SELECT.GENES\n",
    "            select_tabulator.value = df\n",
    "            select_tabulator.visible = True\n",
    "            export_button.visible = True\n",
    "            file_name_input.visible = True\n",
    "\n",
    "        def export(event):\n",
    "            if file_name_input.value == \"\":\n",
    "                debug_str.object = \"Please specify a file name.\"\n",
    "                return 0\n",
    "            gene_df = pd.read_csv('genome_to_protein.csv', index_col=0)\n",
    "            if len(select_tabulator.selection) > 0:\n",
    "                selected_genes = []\n",
    "                out_handle = StringIO()\n",
    "                if enum.value == 1:\n",
    "                    for genome in select_tabulator.selection:\n",
    "                        genome_name = select_tabulator.value.iloc[genome].name\n",
    "                        selected_genes_df = gene_df.loc[(gene_df['genome'] == genome_name)]\n",
    "                        for index, row in selected_genes_df.iterrows():\n",
    "                            selected_genes.append(SeqRecord(Seq(row['sequence']), id=index, description=''))\n",
    "\n",
    "                elif enum.value == 2:\n",
    "                    for cluster in select_tabulator.selection:\n",
    "                        cluster_name = select_tabulator.value.iloc[cluster].name\n",
    "                        for gene in select_tabulator.value.loc[cluster_name]['genes']:\n",
    "                            selected_genes.append(SeqRecord(Seq(gene_df.loc[gene]['sequence']), id=gene, description=''))\n",
    "                else:\n",
    "                    for gene in select_tabulator.selection:\n",
    "                        gene_name = select_tabulator.value.iloc[gene].name\n",
    "                        selected_genes.append(SeqRecord(Seq(select_tabulator.value.loc[gene_name]['sequence']), id=gene_name, description=''))\n",
    "                SeqIO.write(selected_genes, out_handle, \"fasta\")\n",
    "                output_file = f'{export_folder}/{file_name_input.value}.fasta'\n",
    "                with open(output_file, 'w') as output_handle:\n",
    "                        output_handle.write(out_handle.getvalue())\n",
    "                debug_str.object = \"Exporting sequences successfull.\"\n",
    "            else:\n",
    "                debug_str.object = \"Please select at least one checkbox on the right side of the table.\"\n",
    "        \n",
    "        select_export = pn.widgets.Select(name='Select Export', options=['Genomes', 'Clusters', 'Genes'])\n",
    "        select_button = pn.widgets.Button(name='Select', button_type='primary')\n",
    "        select_button.on_click(display)\n",
    "        select_tabulator = pn.widgets.Tabulator(selectable='checkbox', header_filters=True, pagination=\"remote\",  width=1000, height=650, layout='fit_columns', visible = False)\n",
    "        file_name_input = pn.widgets.TextInput(name='Name of export file', placeholder='Enter an identifier for you export file...', visible = False, value = \"\")\n",
    "        export_button = pn.widgets.Button(name='Export Selection', button_type='primary', visible = False)        \n",
    "        export_button.on_click(export)\n",
    "        debug_str = pn.pane.Str(\"\",styles={'font-size': '12pt'})\n",
    "\n",
    "        export_interface = pn.Column(pn.Row(select_export, select_button), pn.Row(select_tabulator, file_name_input,export_button), debug_str)\n",
    "        return export_interface\n",
    "    def panel(self):\n",
    "        return self.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cf67dbd-90e9-4c14-b486-67446d31defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.add_stage('Add Genomes', Genomes)\n",
    "pipeline.add_stage('Clustering Proteins', Diamond)\n",
    "pipeline.add_stage('Pangenome Characteristics', Pan_computation)\n",
    "pipeline.add_stage('Sequence Workbench', Sequence_Workbench)\n",
    "pipeline.add_stage('Blast', Blast)\n",
    "pipeline.add_stage('Geneatlas', Gene_atlas)\n",
    "pipeline.add_stage('Export Data', Export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bd54842-f3c8-4715-b536-0c9b846021b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241m.\u001b[39mservable();\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline.servable();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
